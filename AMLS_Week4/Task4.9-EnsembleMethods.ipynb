{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4.9: Ensemble Methods\n",
    "    Boosting and Bagging Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to implement ensemble methods including boosting and bagging techniques using built-in Scikit Library functions.\n",
    " You will be provided with some already complete code as well as some coding task that you should complete yourself. In particular, you will have to:\n",
    "\n",
    "* complete the function `BaggingClassifierML(X_train, y_train, X_test, k)` that will make use of the pre-built implementation of Bagging techniques.\n",
    "* complete the function `BoostingClassifierML(X_train, y_train, X_test, k)` that will make use of the pre-built implementation of Bagging techniques.\n",
    "* Tune Number of estimator in ensemble methods\n",
    "* Compare the ensemble methods with KNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Import libraries\n",
    "The required libraries for this notebook are pandas, sklearn, numpy and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas import *\n",
    "import pandas as pd\n",
    "from sklearn.datasets import  load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Load the data\n",
    "The data we are using is from iris dataset, which we can access directly from the scikit learn library . It consists of 150 data points and 4 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   Species  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add another column that contains the house prices which in scikit learn datasets are considered as target\n",
    "irisData=load_iris() # get the data\n",
    "print(irisData.data.shape) # shape of data: 150 data points and 4 features\n",
    "print(irisData.feature_names)# Feature_names of data\n",
    "irisData_df=pd.DataFrame(irisData.data,columns=irisData.feature_names) # convert the irisData.data to a a dataframe\n",
    "irisData_df['Species']=irisData.target # there is no column called ‘Species’ in the data frame because the target column is available in another attribute called target\n",
    "newX=irisData_df.drop('Species',axis=1) # All other features\n",
    "newY=irisData_df['Species'] # Species types\n",
    "irisData_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: 0.7  | test set: 0.3\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(newX,newY,test_size=0.3,random_state=3) \n",
    "#test_size= should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split\n",
    "#everytime you run it without specifying random_state, you will get a different result, this is expected behavior\n",
    "#print (len(X_test), len(y_test))\n",
    "\n",
    "print('train set: {}  | test set: {}'.format(round(((len(y_train)*1.0)/len(newX)),3),\n",
    "                                                       round((len(y_test)*1.0)/len(newX),3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Complete the function baggingClassifierML by using Bagging classifier built-in function.\n",
    "Let's find how Bagging Classifier technique can be implemented using already available functions from the scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n",
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "def baggingClassifierML(X_train, y_train, X_test,k):\n",
    "\n",
    "    #Create KNN object with a K coefficient\n",
    "    bagmodel=BaggingClassifier(n_estimators=k,max_samples=0.5, max_features=4,random_state=1)\n",
    "    bagmodel.fit(..., ....) # Fit KNN model\n",
    "\n",
    "\n",
    "    Y_pred = bagmodel.predict(X_test)\n",
    "    #print (Y_pred)\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Your task: Now compute the prediction accuracy score for Bagging technique\n",
    "The accuracy score metric is as follows:\n",
    "\\begin{align}\n",
    "accuracy(y,\\hat{y})=\\frac{1}{n}\\sum_{i=1}^{n} 1(\\hat{y}_i=y_i)\n",
    "\\end{align}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_pred=baggingClassifierML(X_train, y_train, X_test,...)\n",
    "score=metrics.accuracy_score(y_test,....)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Complete the function boostingClassifierML by using Boosting classifier built-in function.\n",
    "\n",
    "AdaBoost (Adaptive Boosting) is a very popular boosting technique that aims at combining multiple weak classifiers to build one strong classifier.\n",
    "Let's find how adaptive Boosting Classifier technique can be implemented using already available functions from the scikit-learn library."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def boostingClassifierML(X_train, y_train, X_test,k):\n",
    "    # AdaBoost takes Decision Tree as its base-estimator model by default.\n",
    "    boostmodel=AdaBoostClassifier(n_estimators=....)\n",
    "    boostmodel.fit(... , y_train,sample_weight=None) # Fit KNN model\n",
    "\n",
    "\n",
    "    Y_pred = boostmodel.predict(X_test)\n",
    "    #print (Y_pred)\n",
    "    return Y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Your task: Now compute the prediction accuracy score for AdaBoosting technique\n",
    "The accuracy score metric is as follows:\n",
    "\\begin{align}\n",
    "accuracy(y,\\hat{y})=\\frac{1}{n}\\sum_{i=1}^{n} 1(\\hat{y}_i=y_i)\n",
    "\\end{align}\n",
    "Now Let's compute the accuracy metric for Adaboosting technique."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_pred1=boostingClassifierML(X_train, y_train, ...,...)\n",
    "score1=metrics.accuracy_score(y_test,...)\n",
    "print(score1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Your task: Tune number of estimators\n",
    "Plot the accuracy metric versus number of base estimator in boosting and bagging ensemble methods.\n",
    "Tune the number of base estimator for better accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Your task: Compare with KNN\n",
    "As you know, ensemble methods including boosting and bagging are used for building a strong classifier.\n",
    "Now, you should compare the result of ensemble methods with KNN in task 4.3 ."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Congrats!\n",
    "Now you have learned how to implement Boosting and Bagging algorithms. There are of course various interesting points we do not cover here, such as  fine tuning various hyper-parameters of boosting and bagging algorithms. With the skills you learned above, you can try it yourselves.\n",
    "You can also compare the ensemble methods with other base learners like Decision Tree and Random Forest.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}